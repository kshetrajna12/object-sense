{"id":"object-sense-03d","title":"Build CLI commands (ingest, show-object, show-type, etc.)","description":"CLI commands: ingest \u003cpath\u003e, show-object \u003cid\u003e, show-type \u003cname\u003e, show-entity \u003cid\u003e, review-types, search \u003cquery\u003e. See concept_v1.md §11 for spec.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-22T20:45:20.354498356-08:00","updated_at":"2025-12-22T21:05:01.432039206-08:00","dependencies":[{"issue_id":"object-sense-03d","depends_on_id":"object-sense-y10","type":"blocks","created_at":"2025-12-22T20:45:59.633068279-08:00","created_by":"daemon"}]}
{"id":"object-sense-1i0","title":"Implement entity resolution and clustering","description":"Soft clustering of observations into entities using late fusion strategy.\n\nSignal combination (priority order):\n1. Hard IDs (product_id, SKU, trip_id) → 1.0 confidence\n2. Same-modality similarity (text↔text via BGE, image↔image via CLIP)\n3. Cross-modal similarity (image↔text via CLIP embeddings)\n\nAlgorithm: weighted_combine(signals) per design_notes.md.\n\nProto-entities compete and stabilize based on confidence scores. See concept_v1.md §4 Step 5 and §5 Layer 2.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-22T20:45:19.536224248-08:00","updated_at":"2025-12-24T20:11:45.237156633-08:00","dependencies":[{"issue_id":"object-sense-1i0","depends_on_id":"object-sense-fj1","type":"blocks","created_at":"2025-12-22T20:45:59.518010975-08:00","created_by":"daemon"}]}
{"id":"object-sense-3rh","title":"Implement type evolution mechanisms (alias, merge, split, deprecate)","description":"Implement type evolution: alias (multiple names→one type), merge (combine types), split (create subtypes), deprecate (soft delete + migrate). See concept_v1.md §7 and design_notes.md 'Type Evolution Mechanisms'.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-22T20:45:19.960300641-08:00","updated_at":"2025-12-22T21:05:01.229444241-08:00","dependencies":[{"issue_id":"object-sense-3rh","depends_on_id":"object-sense-y10","type":"blocks","created_at":"2025-12-22T20:45:59.7423231-08:00","created_by":"daemon"}]}
{"id":"object-sense-5hx","title":"Build Sparkstation embedding client","description":"Create async client wrapper for Sparkstation embedding endpoints.\n\nCapabilities needed:\n- embed_text(texts: list[str]) → list[list[float]] using bge-large (1024-dim)\n- embed_image(images: list[bytes|str]) → list[list[float]] using clip-vit (768-dim)\n- embed_text_clip(texts: list[str]) → list[list[float]] using clip-vit (768-dim)\n\nUse OpenAI SDK with base_url=settings.llm_base_url.\nHandle batching, retries, and errors gracefully.\n\nBlocked by: nothing (can start now)\nBlocks: object-sense-mnz (feature extraction needs this)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-24T20:12:07.402922435-08:00","updated_at":"2025-12-24T20:12:07.402922435-08:00"}
{"id":"object-sense-a1a","title":"Implement medium probing and affordance detection","description":"Detect medium (image/text/json/video/audio/binary) from file headers, extensions, entropy. Map mediums to affordances (can_embed, can_detect_objects, etc.). See concept_v1.md §3.2.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-22T20:45:18.912321271-08:00","updated_at":"2025-12-22T21:04:39.886014502-08:00","dependencies":[{"issue_id":"object-sense-a1a","depends_on_id":"object-sense-y10","type":"blocks","created_at":"2025-12-22T20:45:59.13866307-08:00","created_by":"daemon"}]}
{"id":"object-sense-cqz","title":"OPEN: Unified feature space alignment (visual/textual/structural)","description":"Open question: How do visual embeddings (CLIP), text embeddings, and structural features (schema hashes) align in a unified space? Needed for cross-medium entity clustering. See concept_v1.md §12.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-22T20:45:30.801514541-08:00","updated_at":"2025-12-24T20:04:42.662705291-08:00","closed_at":"2025-12-24T20:04:42.662705291-08:00","close_reason":"Resolved: Late fusion with separate embedding columns (text_embedding 1024, image_embedding 768, clip_text_embedding 768). See design_notes.md."}
{"id":"object-sense-czu","title":"Set up project structure (Python/FastAPI)","description":"Initialize pyproject.toml with UV, create src/object_sense/ layout, configure ruff + pyright, add basic FastAPI app skeleton. See concept_v1.md §11 for tech stack.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T20:45:18.628102441-08:00","updated_at":"2025-12-22T21:15:36.941493459-08:00","closed_at":"2025-12-22T21:15:36.941493459-08:00","close_reason":"Closed"}
{"id":"object-sense-fj1","title":"Implement LLM integration for type inference (tool calling)","description":"Integrate local LLM via tool calling for type inference. LLM queries type store (RAG), proposes primary_type + slots + maybe_new_type. 100% structured outputs. See concept_v1.md §4 Step 4 and §8.2.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-22T20:45:19.156750882-08:00","updated_at":"2025-12-22T21:04:44.421291333-08:00","dependencies":[{"issue_id":"object-sense-fj1","depends_on_id":"object-sense-mnz","type":"blocks","created_at":"2025-12-22T20:45:59.401635524-08:00","created_by":"daemon"}]}
{"id":"object-sense-mnz","title":"Implement feature extraction per medium (image, text, JSON)","description":"Build extractors per medium using Sparkstation models.\n\nEmbeddings per medium (late fusion strategy):\n- Image: image_embedding (CLIP visual 768) + text_embedding (caption→BGE 1024)\n- Text: text_embedding (BGE 1024) + clip_text_embedding (CLIP text 768)\n- JSON: text_embedding (fields→BGE 1024) + hash_value (schema hash)\n- Video: image_embedding (keyframe pool) + text_embedding (transcript→BGE)\n\nModels: bge-large (text), clip-vit (image/text cross-modal).\nOutput: Signature records with embeddings + hash_value + extra metadata.\n\nSee concept_v1.md §4 Step 3, §6, and design_notes.md (late fusion section).","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-22T20:45:19.030456528-08:00","updated_at":"2025-12-24T20:11:55.919788442-08:00","dependencies":[{"issue_id":"object-sense-mnz","depends_on_id":"object-sense-a1a","type":"blocks","created_at":"2025-12-22T20:45:59.285341832-08:00","created_by":"daemon"},{"issue_id":"object-sense-mnz","depends_on_id":"object-sense-5hx","type":"blocks","created_at":"2025-12-24T20:12:11.693932942-08:00","created_by":"daemon"}]}
{"id":"object-sense-x11","title":"OPEN: Proto-entity decay policy","description":"Open question: Proto-entities that never stabilize should be pruned, but rare-but-real entities shouldn't. Need decay based on confidence, not just time/existence. See concept_v1.md §12.","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T20:45:31.112999967-08:00","updated_at":"2025-12-22T21:05:02.240875265-08:00"}
{"id":"object-sense-x98","title":"OPEN: Evidence compaction strategy","description":"Open question: Storing every Evidence record forever doesn't scale. Need strategy to compact/summarize evidence once confidence stabilizes. See concept_v1.md §12.","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T20:45:31.003439848-08:00","updated_at":"2025-12-22T21:05:02.024271298-08:00"}
{"id":"object-sense-y10","title":"Design and implement core data model (Objects, Types, Entities, Evidence)","description":"Implement Postgres schema for core primitives: Object, Type, Entity, Evidence, Signatures. See concept_v1.md §3 and §9 for data model. Use SQLAlchemy or raw SQL with asyncpg.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-22T20:45:18.785546533-08:00","updated_at":"2025-12-22T21:27:09.158812896-08:00","closed_at":"2025-12-22T21:27:09.158812896-08:00","close_reason":"Closed","dependencies":[{"issue_id":"object-sense-y10","depends_on_id":"object-sense-czu","type":"blocks","created_at":"2025-12-22T20:45:56.423723584-08:00","created_by":"daemon"}]}
{"id":"object-sense-yna","title":"OPEN: Fast-path vs slow-path latency strategy","description":"Open question: LLM inference on every blob is expensive. Need fast-path (hash match, deterministic IDs) that skips LLM vs slow-path (full semantic analysis). See concept_v1.md §12.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-22T20:45:30.90684612-08:00","updated_at":"2025-12-22T21:05:01.824452012-08:00"}
