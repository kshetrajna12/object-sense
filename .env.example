# ObjectSense Configuration Example
# Copy this to .env and update with your settings

# ── Database ──────────────────────────────────────────────────────────────────
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/object_sense
DATABASE_ECHO=false

# ── Logging ───────────────────────────────────────────────────────────────────
LOG_LEVEL=INFO
LOG_API_CALLS=false  # Set to true or use --trace flag to see detailed API calls

# ── Provider Selection ────────────────────────────────────────────────────────
# LLM provider for chat/reasoning: "openai" or "sparkstation"
LLM_PROVIDER=sparkstation

# Embedding provider for text embeddings: "openai" or "sparkstation"
# Note: Image embeddings ALWAYS use Sparkstation (cloud providers don't support)
EMBEDDING_PROVIDER=sparkstation

# ── OpenAI Configuration ──────────────────────────────────────────────────────
# Required when LLM_PROVIDER=openai or EMBEDDING_PROVIDER=openai
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# Chat/Reasoning models
OPENAI_MODEL_CHAT=gpt-5.2
OPENAI_MODEL_REASONING=gpt-5.2
# Use gpt-5.2-pro for more complex reasoning (higher cost, better quality)
# OPENAI_MODEL_REASONING=gpt-5.2-pro

# Text embedding model (3072 dimensions)
OPENAI_MODEL_TEXT_EMBEDDING=text-embedding-3-large
OPENAI_DIM_TEXT_EMBEDDING=3072

# ── Sparkstation Configuration ────────────────────────────────────────────────
# Local LLM gateway - always required for image embeddings
# Also used for chat/reasoning when LLM_PROVIDER=sparkstation
# Also used for text embeddings when EMBEDDING_PROVIDER=sparkstation
SPARKSTATION_BASE_URL=http://localhost:8000/v1
SPARKSTATION_API_KEY=dummy-key

# Chat/Reasoning models
SPARKSTATION_MODEL_CHAT=qwen3-vl-4b
SPARKSTATION_MODEL_REASONING=gpt-oss-20b

# Embedding models
SPARKSTATION_MODEL_TEXT_EMBEDDING=bge-large
SPARKSTATION_MODEL_IMAGE_EMBEDDING=clip-vit
SPARKSTATION_DIM_TEXT_EMBEDDING=1024
SPARKSTATION_DIM_IMAGE_EMBEDDING=768

# ── Type Promotion Thresholds ─────────────────────────────────────────────────
TYPE_PROMOTION_MIN_EVIDENCE=5
TYPE_PROMOTION_SURVIVAL_DAYS=7
TYPE_CANDIDATE_REJECT_AFTER_DAYS=30

# ── Entity Resolution Thresholds ──────────────────────────────────────────────
ENTITY_RESOLUTION_T_LINK=0.85
ENTITY_RESOLUTION_T_NEW=0.60
ENTITY_RESOLUTION_T_MARGIN=0.10

# ═══════════════════════════════════════════════════════════════════════════════
# CONFIGURATION MODES
# ═══════════════════════════════════════════════════════════════════════════════

# ── HYBRID MODE (Recommended) ──────────────────────────────────────────────────
# Use OpenAI GPT-5.2 for reasoning + Sparkstation for all embeddings
#
#   LLM_PROVIDER=openai
#   EMBEDDING_PROVIDER=sparkstation
#   OPENAI_API_KEY=sk-...
#   OPENAI_MODEL_REASONING=gpt-5.2
#
# Benefits:
#   ✓ High-quality type inference from GPT-5.2
#   ✓ Fast, free local embeddings (text + image)
#   ✓ No cloud costs for frequent embedding calls
#   ✓ Image embeddings (CLIP) work seamlessly

# ── LOCAL-ONLY MODE ────────────────────────────────────────────────────────────
# Use Sparkstation for everything (default)
#
#   LLM_PROVIDER=sparkstation
#   EMBEDDING_PROVIDER=sparkstation
#
# Benefits:
#   ✓ Fully local, no API costs
#   ✓ Fast inference (no network latency)
#   ✓ Privacy (no data leaves your machine)
#   ✓ Works offline

# ── CLOUD LLM + CLOUD TEXT EMBEDDINGS ──────────────────────────────────────────
# Use OpenAI for LLM and text embeddings + Sparkstation for image embeddings
#
#   LLM_PROVIDER=openai
#   EMBEDDING_PROVIDER=openai
#   OPENAI_API_KEY=sk-...
#   OPENAI_MODEL_REASONING=gpt-5.2
#   OPENAI_MODEL_TEXT_EMBEDDING=text-embedding-3-large
#
# Benefits:
#   ✓ Best LLM quality (GPT-5.2)
#   ✓ Larger text embeddings (3072-dim vs 1024-dim)
#   ✓ Still uses local CLIP for image embeddings (cloud doesn't support)

# ═══════════════════════════════════════════════════════════════════════════════
